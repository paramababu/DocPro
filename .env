CHUNK_MODE=semantic
CHUNK_SIZE=1100
CHUNK_OVERLAP=50

LLAMA_MODEL=llama3.2:3b
TOP_K=5
TEMPERATURE=0.2

EMBEDDINGS_BACKEND=hf
HF_EMBED_MODEL=all-MiniLM-L6-v2
OLLAMA_EMBED_MODEL=nomic-embed-text
